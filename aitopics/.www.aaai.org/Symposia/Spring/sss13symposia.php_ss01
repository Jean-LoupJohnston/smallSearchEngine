<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<link rel="stylesheet" href="https://www.aaai.org/styles/print.css" type="text/css" media="print" />
<link rel="stylesheet" href="https://www.aaai.org/styles/layout.css" type="text/css" media="screen" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<meta http-equiv="Window-target" content="_top" />
<meta name="revisit-after" content="60 days" />
<meta name="robots" content="all" />
<meta name="description" content="AAAI advances the understanding of the mechanisms underlying thought and intelligent behavior and their embodiment in machines." />
<meta name="keywords" content="AAAI AI artificial intelligence" />
<link rel="stylesheet" type="text/css" media="print" href="https://www.aaai.org/styles/printstyles.css" />
<script src="https://www.aaai.org/scripts/popupwindow.js" type="text/javascript"></script>
<title>AAAI 2013 Spring Symposia Registration</title>
<link href="https://www.aaai.org/styles/aaai.css" rel="stylesheet" media="screen" type="text/css" />
<style type="text/css">
<!--
	@import url("https://www.aaai.org/styles/layout.css") screen;
-->
</style>
<style type="text/css">
<!--
	@import url("https://www.aaai.org/styles/print.css") print;
-->
</style>
</head>
<body class="backgrnd2">
<div id="header" class="backgrnd1">
<div id="logo">
<h1>AAAI 2012 Symposia</h1>
</div>
<!-- begin search -->
<div id="search">
<form action="https://www.aaai.org/search-results.php" id="cse-search-box">
  <div>
    <input type="hidden" name="cx" value="016314354884912110518:gwmynp16xuu" />
    <input type="hidden" name="cof" value="FORID:11" />
    <input type="hidden" name="ie" value="UTF-8" />
    <input type="text" name="q" size="31" />
    <input type="submit" name="sa" value="Search" />
  </div>
</form>
<script type="text/javascript" src="https://www.google.com/coop/cse/brand?form=cse-search-box&lang=en"></script>
</div>
</div>
<!-- end search -->
<div id="menu" class="backgrnd3">
<ul class="char11">
<li class="first"><a href="../../../.aaai.org/Organization/organization.php" accesskey="1" title="Information about AAAI, Inc., including bylaws, officers, and staff" class="link1">About Us</a></li>
<li><a href="../../../.aaai.org/Forms/donate.php" accesskey="2" title="Giving to AAAI" class="link1">Gifts</a></li>
<li><a href="http://aitopics.org" rel="nofollow" title="Information about AI (geared especially for students) and AI in the news" class="link1">AITopics</a></li>
<li><a href="../../../.aaai.org/Magazine/magazine.php" accesskey="4" title="AI Magazine pages" class="link1">AI Magazine</a></li>
<li><a href="../../../.aaai.org/Conferences/conferences.php" accesskey="5" title="AAAI, IAAI, and AIIDE conferences" class="link1">Conferences</a></li>
<li><a href="../../../.aaai.org/Library/library.php" accesskey="6" title="Abstracts, with links to full text (for members), of AI papers in the AAAI digital library" class="link1">Library</a></li>
<li><a href="../../../.aaai.org/Membership/membership.php" accesskey="7" title="AAAI Membership Materials" class="link1">Membership</a></li>
<li><a href="../../../.aaai.org/Publications/publications.php" accesskey="8" title="Information for Authors and Links to AI Publications" class="link1">Publications</a></li>
<li><a href="../../../.aaai.org/Symposia/symposia.php" accesskey="9" title="Information about AAAI's spring and fall symposia" class="link1">Symposia</a></li>
<li><a href="../../../.aaai.org/scripts/Contact/contact.php" title="Contact Form" class="link1">Contact</a></li>
</ul>
</div>
<div id="content" class="backgrnd4">
<div id="right">
<div id="box6">
<h2 class="backgrnd12"><span class="text1">AAAI 2013 Spring Symposia</span></h2>
<div class="content">

<p>The Association for the Advancement of Artificial Intelligence is pleased to present the AAAI 2013 Spring Symposium Series, to be held Monday through Wednesday, March 25&ndash;27. The titles of the eight symposia are as follows:</p>

<ul>
<li><a href="sss13symposia.php_ss01"><b>Analyzing Microtext</b></a></li>
<li><a href="http://www.aaai.org/Symposia/Spring/sss13symposia.php#ss02"><b>Creativity and (Early) Cognitive Development</b></a></li>
<li><a href="http://www.aaai.org/Symposia/Spring/sss13symposia.php#ss03"><b>Data Driven Wellness: From Self-Tracking to Behavior Change</b></a></li>
<li><a href="http://www.aaai.org/Symposia/Spring/sss13symposia.php#ss04"><b>Designing Intelligent Robots: Reintegrating AI II</b></a></li>
<li><a href="http://www.aaai.org/Symposia/Spring/sss13symposia.php#ss05"><b>Lifelong Machine Learning</b></a></li>
<li><a href="http://www.aaai.org/Symposia/Spring/sss13symposia.php#ss06"><b>Shikakeology: Designing Triggers for Behavior Change</b></a></li>
<li><a href="http://www.aaai.org/Symposia/Spring/sss13symposia.php#ss07"><b>Trust and Autonomous Systems</b></a></li>
<li><a href="http://www.aaai.org/Symposia/Spring/sss13symposia.php#ss08"><b>Weakly Supervised Learning from Multimedia</b></a></li>
</ul>



<div class="hr1">
<hr />
</div>


<h3 class="text1"><a name="ss01">Analyzing Microtext</a></h3>
<h5><a href="http://www.regonline.com/aaaisss13" rel="nofollow">Register Online Now!</a></h5>
<p>
Microtext are short snippets of text found in many modes of communication: microblogs (such as, Twitter, Plurk), short message streams (SMS), chat (such as instant messaging, internet relay chat), and transcribed conversations (such as FBI hostage negotiations). Microtext often has the characteristics of informality, brevity, varied grammar, frequent misspellings (both accidental and purposeful), and usage of abbreviations, acronyms, and emoticons. With more conversational forms of microtext such as multiparticipant chat, there are also entangled conversation threads. These characteristics create many difficulties for analyzing and understanding microtext, often causing traditional NLP techniques to fail.
</p>

<p>
Research on microtext is becoming increasingly necessary given the explosion of online microtext language. Yet, very few suitable tools have been developed for analyzing it. Also, there are few sufficiently large, publicly-available data sets (such as the Twitter corpus). Currently, most NLP tools are designed to deal with grammatical, properly spelled and punctuated language corpora. However, the reality is that a vast portion of online data does not conform to the canons of standard grammar and spelling. 
</p>

<p>
This symposium will provide a multiday forum to bring together researchers from different communities who have an interest in analyzing microtext: artificial intelligence, machine learning, computational linguistics, information retrieval, linguistics, human-computer interaction, education, and the social sciences. It will provide enough time for the different communities to present their perspectives and methodologies, to learn one another&rsquo;s terminology and techniques, and to begin to form connections that will hopefully lead to fruitful collaborations. This symposium will include invited talks, paper presentations (oral and poster), panels, and discussions.
</p>

<h5>Topics</h5>
<p>
Topics of interest include, but are not limited to the following:
</p>

<ul>
<li>Identification of message characteristics (for example, relevancy, centrality, repeatability, trustworthiness)</li>
<li>Creation of participant profile (for example, age, gender, expertise topics, emotional states, social roles)</li>
<li>Author attribution</li>
<li>Topic detection and monitoring</li>
<li>Topic to subtopic decomposition and topic stage evolution tracking and prediction</li>
<li>Thread summarization</li>
<li>Modeling of influence and attitude changes</li>
<li>Corpus creation</li>
<li>Language structure (for example, part of speech, dialogue acts, speech acts)</li>
<li>Visualization</li>
</ul>

<h5>Organizing Committee</h5>
<p>
Eduard Hovy (Carnegie Mellon University), Vita Markman (Disney Interactive Media Group), Craig Martell (Naval Postgraduate School), David Uthus (National Research Council and Naval Research Laboratory)
</p>


<h5>For More Information</h5>
<p>
For more information, please consult the <a href="http://www.daviduthus.org/meetings/SAM2013" rel="nofollow">supplemental symposium website.</a>
</p>



<div class="hr1">
<hr />
</div>


<h3 class="text1"><a name="ss02">Creativity and (Early) Cognitive Development: A Perspective from Artificial Creativity, Developmental AI and Robotics</a></h3>
<h5><a href="http://www.regonline.com/aaaisss13" rel="nofollow">Register Online Now!</a></h5>
<p>
Cross-domain general creativity is probably a uniquely human faculty. From a child who constructs a new toy using the old and broken ones, to the scientist who works out a theory and makes a profound impact on human civilization, the process invariably evokes the feelings of surprise, astonishment, and wonder. Though we understand what creativity is at an intuitive level, it has turned out to be quite difficult to define it formally and explore it scientifically. 
</p>

<p>
Some researchers of creativity make a distinction between historical-creativity and psychological-creativity. H-creativity is a subset of P-creativity and is about exceptional, so far not-seen creative endeavor in particular society. P-creativity is about small creative deeds, probably new only to the individual performing them. We hypothesize that they share the same basic cognitive mechanisms. We further hypothesize that creative perception (in viewing an artifact) involves the same mechanisms that are responsible for generating creative artifacts. Moreover, these mechanisms can also be observed during cognitive development: a constant reconceptualization of one&rsquo;s understanding of their environment in the process of agent-environment interaction, maturation, and education. If this hypothesis is accepted, then it suggests that by exercising and stimulating creative perception, we can also strengthen the ability to generate creative ideas and artifacts in the individual.
</p>

<p>
The goal of this symposium is to explore this framework, and its implications for various aspects of creativity. The target audiences for this symposium are researchers from artificial creativity, developmental psychology, and developmental robotics.
</p>
 
<h5>Topics</h5>
<p>
Topics of interest include, but are not limited to the following:
</p>


<ul>
<li>H-creativity versus P-creativity: qualitative or quantitative distinction</li>
<li>Reasoning by analogy and creativity</li>
<li>Creativity research in early infancy</li>
<li>Analogy research in early infancy</li>
<li>Pretense play and creativity</li>
<li>Atypical cognitive development and creativity</li>
<li>Computational models of creative leaps</li>
<li>Computational models of creativity via analogy</li>
</ul>
 
<h5>Format</h5>
<p>
The format of the symposium will include brief presentations (15&ndash;20 minutes maximum, followed by questions), poster sessions, and a panel discussion.
</p>


<h5>Cochairs</h5>
<p>
Georgi Stojanov<br />
The American University of Paris<br />
147, rue de Grenelle<br />
75007 Paris, France<br />
&#103;&#115;&#116;&#111;&#106;&#97;&#110;&#111;&#118;&#64;&#97;&#117;&#112;&#46;&#101;&#100;&#117;
</p>

<p>
Bipin Indurkhya <br />
International Institute of Technology, Hyderabad (India)<br />
AGH University of Science and Technology<br />
al Mickiewicz 30, 30-059 Cracow, Poland<br />
&#98;&#105;&#112;&#105;&#110;&#64;&#97;&#103;&#104;&#46;&#101;&#100;&#117;&#46;&#112;&#108;
</p>

<h5>Organizing Committee</h5>
<p>
Mohammad Majid al-Rifaie (University of London, UK, &#109;&#46;&#109;&#97;&#106;&#105;&#100;&#64;&#103;&#111;&#108;&#100;&#46;&#97;&#99;&#46;&#117;&#107;), Matthew Schlesinger (SIU in Carbondale, Illinois, USA, &#109;&#97;&#116;&#116;&#104;&#101;&#119;&#115;&#64;&#115;&#105;&#117;&#46;&#101;&#100;&#117;), Goran Trajkovski (Virginia International University, USA, &#103;&#111;&#114;&#97;&#110;&#46;&#116;&#114;&#97;&#106;&#107;&#111;&#118;&#115;&#107;&#105;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;)
</p>

<h5>For More Information</h5>
<p>
For more information, please consult the <a href="https://sites.google.com/site/ccdev2013/home" rel="nofollow">supplemental symposium website.</a>
</p>



<div class="hr1">
<hr />
</div>


<h3 class="text1"><a name="ss03">Data Driven Wellness: From Self Tracking to Behavior Change</a></h3>
<h5><a href="http://www.regonline.com/aaaisss13" rel="nofollow">Register Online Now!</a></h5>
<p>
This symposium focuses on &ldquo;data driven wellness&rdquo; which derives behavior change from our daily life starting from self tracking of our health. For example, when we know our genome information (for example, a possibility of being diabetes) from our saliva (that is, self tracking), our mind changes to not eat high-calorie foods or to start running to keep or lose our weight (that is, behavior change). Such an important stream of improving our health is promoted owing to a lot of data of our health (that is, data driven wellness) acquired by current technologies (for example, calories calculation by smart phone), and these streams contribute to creating society or social activities on health improvement (for example, society or social activities that supports diabetes patients). Our symposium explores such AI technologies and discusses possible solutions for our wellness.
</p>

<h5>Topics of Interest</h5>
<p>
Topics of interest include, but are not limited to the following:
</p>


<ol>
<li><i>Self tracking technology:</i> sleep monitoring, diet monitoring, vital data, diabetes monitoring, running/sport calorie monitoring, personal genome, personal medicine, new type of self tracking device, portable mobile tools</li>

<li><i>Behavior change analysis and platform:</i> behavior change/activation, awareness, mindfulness, citizen science platform (quantified self, DIY trials), compassion, calming technology, health care communication, science discovery</li>

<li><i>Cognitive and biomedical modeling:</i> brain science, physiological modeling, biomedical informatics, systems biology, network analysis, mathematical modeling</li>

<li><i>Data driven wellness and collective intelligence:</i> data mining and knowledge modeling for wellness, collective intelligence/ knowledge, life log analysis, case studies, data visualization, human computation</li>

<li><i>Wellness service applications and field study:</i> medical recommendation system, care support system for aged person, web service for personal wellness, games for health and happiness, life log applications, disease improvement experiment (for example, metabolic syndrome, diabetes), sleep improvement experiment</li>
</ol>


<h5>Invited Speakers</h5>
<p>
Invited speakers will include Koiti Hasida (National Institute of Advanced Industrial Science and Technology, Japan), Chirag Patel (Stanford University, Japan), and Esther Dyson (23andMe, Inc., USA)
</p>

<h5>Organizing Committee</h5>
<p>
Takashi Kido (Riken Genesis Co. LTD, Japan) and Keiki Takadama (The University of Electro-Communications, Japan)
</p>

<h5>For More Information</h5>
<p>
For more information, please consult the <a href="https://sites.google.com/site/datadrivenwellness/cfp" rel="nofollow">supplemental symposium website.</a>
</p>



<div class="hr1">
<hr />
</div>


<h3 class="text1"><a name="ss04">Designing Intelligent Robots: Reintegrating AI</a></h3>
<h5><a href="http://www.regonline.com/aaaisss13" rel="nofollow">Register Online Now!</a></h5>
<p>The goal of building intelligent robots has been a motivating problem for generations of 
AI researchers, going back at least as far as Shakey the robot in 1966. Creating such a robot is both the fully realized expression of the original impulse behind AI and an immensely rich source of research questions that address real-world problems.
</p>

<p>
However, AI is a fragmented field: well-developed and largely independent research communities exist for learning, planning, reasoning, language, perception and control. Since the challenges posted by each of these subfields are immense, most researchers have found it necessary to devote their careers to specializing in a single subfield. While immense progress has been made in each of these subfields in the last few decades, it remains unclear how they can be integrated to produce an intelligent robot. Unifying these disparate technologies will open up new avenues of research and create new application opportunities. Therefore, we believe that integration should be considered a valid research endeavor in its own right.
</p>

<p>
This symposium aims to bring together a diverse and multidisciplinary group of researchers interested in the specific objective of designing intelligent robots. The first such symposium, held in 2012, resulted in many interesting discussions across subfields, and the current one aims to continue these interactions, thereby actively encouraging the integration of various AI techniques. We also hope to foster an active discussion about setting a realistic and feasible medium-term objective for integrative research so that progress can be made. The symposium will include invited talks as well as a poster session with ample time for discussion.
</p>

<h5>Organizing Committee</h5>
<p>
Byron Boots (Carnegie Mellon University), Nick Hawes (University of Birmingham), Todd Hester (University of Texas), George Konidaris (Massachusetts Institute of Technology), Bhaskara Marthi (Willow Garage), Benjamin Rosman (University of Edinburgh), Lorenzo Riano (University of California, Berkeley)
</p>

<h5>For More Information</h5>
<p>
For more information, please consult the <a href="http://people.csail.mit.edu/gdk/dir2/" rel="nofollow">supplemental symposium website.</a>
</p>



<div class="hr1">
<hr />
</div>


<h3 class="text1"><a name="ss05">Lifelong Machine Learning</a></h3>
<h5><a href="http://www.regonline.com/aaaisss13" rel="nofollow">Register Online Now!</a></h5>
<p>
Humans learn to solve increasingly complex tasks by continually building upon and refining knowledge over a lifetime of experience. This process of continual learning and transfer allows us to rapidly learn new tasks, often with very little training. Over time, it enables us to develop a wide variety of complex abilities across many domains.
</p>

<p>
Despite recent advances in transfer learning and representation discovery, lifelong machine learning remains a largely unsolved problem. Lifelong machine learning has the huge potential to enable versatile systems that are capable of learning a large variety of tasks and rapidly acquiring new abilities. These systems would benefit numerous applications, such as medical diagnosis, virtual personal assistants, autonomous robots, visual scene understanding, language translation, and many others.
</p>

<p>
Learning over a lifetime of experience involves a number of procedures that must be performed continually, including the following:
</p>

<ol>
<li>Discovering representations from raw sensory data that capture higher-level abstractions, </li>

<li>Transferring knowledge learned on previous tasks to improve learning on the current task, </li>

<li>Maintaining the repository of accumulated knowledge, and </li>

<li>Incorporating external guidance and feedback from humans or other agents.</li>
</ol>

<p>
Each of these procedures encompasses one or more subfields of machine learning and artificial intelligence. The primary goal of this symposium is to bring together practitioners in each of these areas and focus discussion on combining these lines of research toward lifelong machine learning.
</p>

<h5>Topics</h5>
<p>
The symposium will include paper presentations, talks, and discussions on a variety of topics related to lifelong learning, including but not limited to the following: 
</p>

<ul>
<li><i>knowledge transfer:</i> active transfer learning, multitask learning, cross-domain transfer, source knowledge selection, one-shot learning, and transfer over long sequences of tasks </li>

<li><i>continual learning:</i> online multitask learning, knowledge maintenance, developmental learning, scalable transfer, task/concept drift, and selfselection of tasks </li>

<li><i>representation discovery:</i> deep learning, latent representations, multimodal/multiview learning, and multiscale representations </li>

<li><i>incorporating guidance from external teachers:</i> learning from demonstration, skill shaping, curriculum-based training, interactive learning, and agent-teacher communication </li>

<li><i>frameworks for lifelong learning:</i> architectures, software frameworks, data sets, testbeds, and evaluation methodologies </li>

<li><i>applications of lifelong learning</i></li>
</ul>

<p>
Within these topics, the symposium will explore lifelong learning in difierent problem formats, including classification, regression, and sequential decision-making problems.
</p>

<h5>Organizing Committee</h5>
<p>
Eric Eaton, chair (Bryn Mawr College), Terran Lane (Google), Honglak Lee (University of Michigan), Michael Littman (Brown University), Fei Sha (University of Southern California), Thomas Walsh (University of Kansas)
</p>

<h5>For More Information</h5>
<p>
For more information, please consult the <a href="http://cs.brynmawr.edu/~eeaton/AAAI-SSS13-LML/" rel="nofollow">supplemental symposium website.</a>
</p>



<div class="hr1">
<hr />
</div>


<h3 class="text1"><a name="ss06">Shikakeology: Designing Triggers for Behavior Change</a></h3>
<h5><a href="http://www.regonline.com/aaaisss13" rel="nofollow">Register Online Now!</a></h5>
<p>
How do you trigger learning by seeing?
How do you encourage ecoconscious behaviors?
How do you trigger health awareness?
How do you encourage crime prevention?
</p>

<p>
Shikake is a Japanese word that represents embodied trigger for implicit or explicit behavior change to solve problems. The aim of this symposium is to gain a holistic understanding of Shikake, that is: Shikake principles, behavior change triggers, sustained behavior change, case studies, approaches to design simple and complex Shikake.
</p>

<p>
The merits of Shikakeological approach are summarized by four points; low expertise, low cost, wide range of target users, and long term continuous behavior changes. Developing a Shikake can be easier and less expensive than developing complicated engineering mechanism. These advantages allow people to use the Shikake approach to address immediate problems without requiring specific expertise.
</p>

<p>
Another Shikake objective is to induce spontaneous behavior. When people feel controlled or forced by someone or something to do something, they never do that again. On the other hand, if people desire and enjoy changing their behavior, they would do it repeatedly. Shikake aims to change behavior through a continuous engagement and transformation process.
</p>

<p>
The goal of Shikakeology is to codify the cause and effect of Shikake cases from physical or psychological points of view, and to establish a Shikake design methodology. To achieve this goal, this workshop invites Shikake studies to share the knowledge, methods, experiments and findings that demonstrate triggers that motivate people and lead to behavior changes.
</p>

<p>
We will have two keynote presentations, one panel discussion, and 25 oral presentations, all of which are related or contribute to the study of Shikake. 
</p>

<h5>Organizing Committee</h5>
<p>
Naohiro Matsumura (Osaka University), Renate Fruchter (Stanford University)
</p>

<h5>For More Information</h5>
<p>
For more information, please consult the <a href="http://mtmr.jp/aaai2013/" rel="nofollow">supplemental symposium website.</a>
</p>



<div class="hr1">
<hr />
</div>


<h3 class="text1"><a name="ss07">Trust and Autonomous Systems</a></h3>
<h5><a href="http://www.regonline.com/aaaisss13" rel="nofollow">Register Online Now!</a></h5>
<p>
Trust is a key issue in the development and implementation of autonomous systems working with humans. Humans must be able to trust the actions of the machines to want to work with them, and machines must develop or establish trust in the actions of human coworkers to ensure effective collaboration. There is also the issue of autonomous agents, robots and systems trusting one another and humans.
</p>

<p>
But trust can mean different things in different contexts. For flight control systems on airplanes, trust may mean meeting rigorous criteria regarding structural qualities of the airplane, flightworthiness, and a provably stable control system. In the context of humans interacting with humanoid robots, trust may more closely relate to the interdependence between the human and robot in correctly reading and interpreting each other&rsquo;s voice commands and gestures and observed actions, and the likelihood that both the robot and human will do what is expected of each other. In the context of an autonomous automobile carrying passengers, trust in the system may be the expectation that the system will respond correctly not only to foreseen road and traffic conditions, but also to unusual circumstances (for example, gridlock; alternative route planning; a child running into the street; running out of gas on the highway; an engine catching fire; hearing a fire engine or ambulance with siren blaring; or a flat tire causing the vehicle to swerve). Interdependent trust also includes system controllers and society. System controllers, human or machine, must be able to control at the individual, group and system levels; and society must be willing to entrust its citizens, including the elderly and young, to the system.
</p>

<p>
This symposium will explore the various meaning aspects and meanings of trust between humans and machines in various situational contexts, and the social dynamics of trust in teams or organizations composed of autonomous machines working together with humans. We will seek to identify and/or develop methods for engendering trust between humans and autonomous machines, to consider the static and dynamic aspects of trust, and to propose metrics for measuring trust. 
</p>

<h4>Invited Speakers</h4>
<p>
Keynote speakers will include John Lee (University of Wisconsin)
Missy Cummings (ONR/MIT), 
Joseph Lyons (AFOSR), 
Jeff Bradshaw (IHMC), 
Holly Yanco (UMass Lowell), and 
Ron Diftler (NASA/JSC Robonaut)
</p>

<h5>Organizing Committee</h5>
Don Sofge (Naval Research Laboratory; &#100;&#111;&#110;&#46;&#115;&#111;&#102;&#103;&#101;&#64;&#110;&#114;&#108;&#46;&#110;&#97;&#118;&#121;&#46;&#109;&#105;&#108;), Geert-Jan Kruijff (German Research Center for AI (DFKI); &#103;&#106;&#64;&#100;&#102;&#107;&#105;&#46;&#100;&#101;), William F. Lawless, Paine College; &#119;&#108;&#97;&#119;&#108;&#101;&#115;&#115;&#64;&#112;&#97;&#105;&#110;&#101;&#46;&#101;&#100;&#117;)

<h5>For More Information</h5>
<p>
For more information, please consult the <a href="https://sites.google.com/site/aaais2013trust/" rel="nofollow">supplemental symposium website.</a>
</p>



<div class="hr1">
<hr />
</div>


<h3 class="text1"><a name="ss08">Weakly Supervised Learning from Multimedia</a></h3>
<h5><a href="http://www.regonline.com/aaaisss13" rel="nofollow">Register Online Now!</a></h5>
<p>
What can computers learn about the real world from large quantities of audio-visual data, with minimal human supervision? While weakly supervised learning has been an active research topic in the natural language community, learning from large multimedia collections (and video in particular) is a field that is still in its infancy. Early efforts in this direction include learning models of objects and actions from internet video, humans in images and localizing sounds in audio.
</p>

<h5>Topics</h5>
Topics of interest for the symposium include the following:
<ul>
<li>Scaling weakly supervised learning to very large collections (for example, internet video)</li>
<li>Features and representations</li>
<li>Weakly supervised learning algorithms and connections to related topics, such as multiple instance learning and semisupervised learning</li>
<li>Learning in the presence of significant label noise</li>
<li>Value of "seeding" weakly supervised learning with small amounts of strongly supervised data</li>
<li>Datasets to enable direct comparison of approaches, including challenges in obtaining reliable groundtruth annotations</li>
<li>Transfer learning (for example, learning from video and testing in the image domain)</li>
<li>Weakly supervised approaches in robotics</li>
<li>Combining audio/visual content with text</li>
<li>Challenge problems in audio, image, video and multimodal domains</li>
</ul>
<h5>Format</h5>
<p>
The symposium will consist of presentations from several invited speakers, presentations selected from position papers, an open poster session, and panel discussions about key issues (such as publicly available datasets). The sessions will be organized so as to provide ample opportunities for unstructured discussion.
</p>

<h5>Chair</h5>
<p>
Rahul Sukthankar (Google Research and Carnegie Mellon University, &#114;&#97;&#104;&#117;&#108;&#115;&#64;&#99;&#115;&#46;&#99;&#109;&#117;&#46;&#101;&#100;&#117;)
</p>

<h5>Organizing Committee</h5>
<p>
Omid Madani (Google, &#109;&#97;&#100;&#97;&#110;&#105;&#64;&#103;&#111;&#111;&#103;&#108;&#101;&#46;&#99;&#111;&#109;), James M. Rehg (Georgia Tech, &#114;&#101;&#104;&#103;&#64;&#99;&#99;&#46;&#103;&#97;&#116;&#101;&#99;&#104;&#46;&#101;&#100;&#117;), Rahul Sukthankar (Google Research and Carnegie Mellon, &#114;&#97;&#104;&#117;&#108;&#115;&#64;&#99;&#115;&#46;&#99;&#109;&#117;&#46;&#101;&#100;&#117;)
</p>

<h5>For More Information</h5>
<p>
For more information, please consult the <a href="https://sites.google.com/site/wslmm2013/" rel="nofollow">supplemental symposium website</a>.
</p>






<div class="hr1">
<hr />
</div>


 
</div>
</div>
</div>

<div id="left">
<div id="box4">
<h2 class="backgrnd5"><span class="text1">AAAI Symposia</span></h2>
<div class="content">
<h3 class="text2"><a href="https://aaai.org/Symposia/Fall/fall-symposia.php" title="AAAI fall symposia pages">AAAI Fall Symposia</a></h3>
<h3 class="text2"><a href="https://aaai.org/Symposia/Spring/spring-symposia.php" title="AAAI spring symposia pages">AAAI Spring Symposia</a></h3>
<h3 class="text2"><a href="https://aaai.org/Symposia/EAAI/eaai-symposia.php" title="AAAI Educational Advances in AI Symposia">AAAI Educational Advances in AI Symposia</a></h3>
<h3 class="text2"><a href="https://aaai.org/Press/Reports/reports.php" title="aaai technical reports">Technical Reports</a></h3>
<h3 class="text2"><a href="https://aaai.org/Publications/Author/author.php" title="forms and instructions for accepted authors">For Accepted Authors</a></h3> 
</div>

<h4 class="backgrnd5"><span class="text1">Other Links</span></h4>
<div class="content">
<h3 class="text2"><a href="../../../.aaai.org/home.php" title="AAAI Home Page">AAAI Home Page</a></h3> 
<h3 class="text2"><a href="../../../.aaai.org/Awards/awards.php" title="Fellows and Awards Pages">Awards</a></h3> 
<h3 class="text2"><a href="../../../.aaai.org/Magazine/calendar.php" title="International Calendar of AI Events">Calendar</a></h3> 
<h3 class="text2"><a href="../../../.aaai.org/Magazine/job-bank.php" title="Jobs for AI Scientists">Jobs</a></h3> 
<h3 class="text2"><a href="../../../.aaai.org/Meetings/meetings.php" title="AAAI Sponsored and Affiliated Conferences, Workshops, and Symposia">Meetings</a></h3> 
<h3 class="text2"><a href="../../../.aaai.org/Press/press.php" title="AI books, proceedings, and technical reports">AAAI Press</a></h3> 
<h3 class="text2"><a href="../../../.aaai.org/Resources/resources.php" title="Links to Outside AI Pages">Resources</a></h3> 
<h3 class="text2"><a href="../../../.aaai.org/Workshops/workshops.php" title="Information about AAAI sponsored workshops">AAAI Workshops</a></h3>
</div>
</div>
</div>
<div style="clear: both;">
</div>
</div>




<div id="footer" class="backgrnd11">
<p class="text3"><a href="https://twitter.com/RealAAAI" class="twitter-follow-button" data-show-count="false">Follow @RealAAAI</a><script async src="../../../.platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p class="text3">This site is protected by copyright and trademark laws under US and International law. All rights reserved. <a href="../../../.aaai.org/Organization/copyright.php">Copyright</a> &copy; 1995&ndash;2019 Association for the Advancement of Artificial Intelligence.<br />Your use of this site is subject to our <a href="../../../.aaai.org/Organization/terms.php">Terms and Conditions</a> and <a href="../../../.aaai.org/Organization/privacy.php">Privacy Policy</a>&nbsp;|&nbsp;<a href="../../../.aaai.org/home.php" title="AAAI Home Page">Home</a>&nbsp;|&nbsp;<a href="../../../.aaai.org/Organization/organization.php" title="Information about AAAI, Inc., including bylaws, officers, and staff">About AAAI</a>&nbsp;|&nbsp;<a href="https://aaai.org/Organization/search.php" title="Search the AAAI Web Site">Search</a>&nbsp;|&nbsp;<a href="../../../.aaai.org/scripts/Contact/contact.php" title="Send a Message to AAAI">Contact&nbsp;AAAI</a><br />
<a href="../../../.aaai.org/Conferences/conferences.php" title="AAAI, IAAI, and AIIDE conferences">AAAI Conferences</a>&nbsp;|&nbsp;<a href="../../../.aaai.org/Magazine/magazine.php" title="AI Magazine home page">AI Magazine</a>&nbsp;|&nbsp;<a href="http://aitopics.org" title="Information about AI (geared especially for students) and AI in the news" rel="nofollow">AITopics</a>&nbsp;|&nbsp;<a href="../../../.aaai.org/Awards/awards.php" title="Fellows and Awards Pages">Awards</a>&nbsp;|&nbsp;<a href="../../../.aaai.org/Magazine/calendar.php" title="International Calendar of AI Events">Calendar</a>&nbsp;|&nbsp;<a href="../../../.aaai.org/Library/library.php" title="Abstracts, with links to full text (for members), of AI papers in the AAAI digital library">Digital Library</a>&nbsp;|&nbsp;<a href="../../../.aaai.org/Magazine/job-bank.php" title="Jobs for AI Scientists">Jobs</a>&nbsp;|&nbsp;<a href="../../../.aaai.org/Meetings/meetings.php" title="AAAI Sponsored and Affiliated Conferences, Workshops, and Symposia">Meetings</a>&nbsp;|&nbsp;<a href="../../../.aaai.org/Membership/membership.php" title="AAAI Membership Materials">Membership</a>&nbsp;|&nbsp;<a href="../../../.aaai.org/Press/press.php" title="AI books, proceedings, and technical reports">Press</a>&nbsp;|&nbsp;<a href="../../../.aaai.org/Pressroom/pressroom.php" title="News Releases and Information for Journalists">Press Room</a>&nbsp;|&nbsp;<a href="../../../.aaai.org/Publications/publications.php" title="Information for Authors and Links to AI Publications">Publications</a>&nbsp;|&nbsp;<a href="../../../.aaai.org/Resources/resources.php" title="Links to Outside AI Pages">Resources</a>&nbsp;|&nbsp;<a href="../../../.aaai.org/Symposia/symposia.php" title="Information about AAAI's spring and fall symposia">Symposia</a>&nbsp;|&nbsp;<a href="../../../.aaai.org/Workshops/workshops.php" title="Information about AAAI sponsored workshops,">Workshops</a></p>
</div>
<!-- <table width="135" border="0" cellpadding="2" cellspacing="0" title="Click to Verify - This site chose Symantec SSL for secure e-commerce and confidential communications.">
<tr>
<td width="135" align="center" valign="top"><script type="text/javascript" src="https://seal.verisign.com/getseal?host_name=www.aaai.org&amp;size=XS&amp;use_flash=NO&amp;use_transparent=NO&amp;lang=en"></script><br />
<a href="http://www.symantec.com/verisign/ssl-certificates" target="_blank"  style="color:#000000; text-decoration:none; font:bold 7px verdana,sans-serif; letter-spacing:.5px; text-align:center; margin:0px; padding:0px;">ABOUT SSL CERTIFICATES</a></td>
</tr>
</table>-->
</body>
</html>
